libraries = c("mvtnorm", "hdm", "pracma", "np", "sandwich", "flare", "doSNOW", "AER")
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
install.packages(x)
})
lapply(libraries, library, quietly = TRUE, character.only = TRUE)
# single target variable in each equation
med.iv = function(alpha, y, x, z){
u = y - alpha*x
phi = rep(0,length(u))
for(t in 1:length(u)){
if(u[t]<=0){phi[t]=-0.5}else{phi[t]=0.5}
}
4*mean(phi*z)^2/mean(z^2)
}
rep = 100
nboot = 100
T = 100
K = 100
M = 20
bn = 4 #length of block
rho = 0.5
rho.var = 0.1
lag = 1
dx = 5
dd = 5
cd = 0.25
cy = 0.5
c1 = makeCluster(4) # core numbers: cohen 20 cores
registerDoSNOW(c1)
results = list()
sim_scene = function(nboot,T,K,M,rho,rho.var,lag,dx,dd,cd,cy,bn){
#for(r in 1:rep){
lambda.ga = 2*1.1*qnorm(1-0.1/(2*K*M))
alpha = c(rep(1,M/2),rep(0,M/2))
ln = T/bn #number of blocks
beta.matrix = matrix(0, M, K)
for (m in 1:M){
indx = ceiling(m/dd)
beta.matrix[m, (dd*(indx-1)+1):(indx*dd)] = cy/c(1:dd)
}
theta.matrix = matrix(0, M, K)
for (m in 1:M){
indx = ceiling(m/dd)
theta.matrix[m, (dd*(indx-1)+1):(indx*dd)] = cd/c(1:dd)
}
Phi = bdiag(matrix(rho.var,dx,dx))
for(pp in 1:(K/dx-1)){
Phi = bdiag(Phi,matrix(rho.var,dx,dx))
}
Phi = as.matrix(Phi)
Y = matrix(0,T,M)
d = matrix(0,T,M)
v = matrix(0,T,M)
psi = matrix(0,T,M)
load = matrix(0,M,K)
load1 = matrix(0,M,K+1)
beta.matrix.hat = matrix(0,M,K)
theta.matrix.hat = matrix(0,M,K)
intercept.hat = rep(0,M)
e = matrix(0, nrow = T, ncol = M)
c = rep(0, nboot)
Smatrix.boot  = array(0,dim=c(M,K,nboot))
Smatrix.boot1  = array(0,dim=c(M,K+1,nboot))
omega = rep(0, M)
phi = rep(0, M)
upper_0.05 = rep(0, M)
lower_0.05 = rep(0, M)
upper.boot_0.05 = rep(0, M)
lower.boot_0.05 = rep(0, M)
stat.boot = matrix(0, nboot, M)
alpha.hat = rep(0,M)
alpha0.hat = rep(0,M)
sigma = rep(0,M)
length_0.05 = rep(0,M)
reject_0.05 = rep(0,M)
length.boot_0.05 = rep(0,M)
reject.boot_0.05 = rep(0,M)
reject.boot.multi_0.05_temp = rep(0,M)
reject.boot.multi_0.05 = rep(0,M)
reject.boot.simul_0.05 = 0
## errors~AR(1)
innov1  = rmvnorm(T, rep(0,M), diag(M))
innov2  = rmvnorm(T, rep(0,M), diag(M))
for (t in 2:T) {
innov1[t,] = rho * innov1[t-1,] + rnorm(1)
innov2[t,] = rho * innov2[t-1,] + rnorm(1)
}
## X~VAR(lag)
X = matrix(0,nrow=T+lag,ncol=K)
innov = rmvnorm((T+lag), rep(0,K), diag(K))
X[1,] = innov[1,]
for(t in 2:(T+lag)){
X[t,] = Phi %*% X[t-lag,] + innov[t,]
}
X = X[-1,]
## joint penalty level (for step 1)
for (m in 1:M){
d[,m] = X %*% theta.matrix[m,] + innov1[,m]
#d[,m] = scale(d[,m])
Y[,m] = alpha[m]*d[,m] + X %*% beta.matrix[m,] + innov2[,m]
#Y[,m] = scale(Y[,m])
#X = scale(X)
X.all = cbind(d[,m], X)
fit0 = rlasso(X.all, Y[,m], penalty = list(homoscedastic = "none", lambda.start = 2*0.5*sqrt(T)*qnorm(1-0.1/(2*(K+1)))), post=FALSE)
#load1[m,] = fit0$loadings
e[,m] = Y[,m] - predict(fit0)
for (j in 1:nboot){
e.boot = rnorm(ln)
for (k in 1:(K+1)){
sum = 0
for (l in 1:ln){
sum = sum + sum(X.all[((l-1)*bn+1):(l*bn),k]*e[((l-1)*bn+1):(l*bn),m])*e.boot[l]
}
Smatrix.boot1[m,k,j] = sum/sqrt(T)
}
}
#### compute the penalty loadings
for(k in 1:(K+1)){
load1[m,k] = sqrt(lrvar(X.all[,k]*e[,m])*T)
}
}
for(j in 1:nboot){
c[j]=max(abs(Smatrix.boot1[,,j]/load1))
}
lambda.boot1 = 2*quantile(c, 0.9)*sqrt(T)*1.1
## joint penalty level (for step 2)
for (m in 1:M){
fit0 =  rlasso(X, d[,m], penalty = list(homoscedastic = "none", lambda.start = 2*0.5*sqrt(T)*qnorm(1-0.1/(2*K))), post=FALSE)
#load[m,] = fit0$loadings
e[,m] = d[,m] - predict(fit0)
for (j in 1:nboot){
e.boot = rnorm(ln)
for (k in 1:K){
sum = 0
for (l in 1:ln){
sum = sum + sum(X[((l-1)*bn+1):(l*bn),k]*e[((l-1)*bn+1):(l*bn),m])*e.boot[l]
}
Smatrix.boot[m,k,j] = sum/sqrt(T)
}
}
#### compute the penalty loadings
for(k in 1:K){
load[m,k] = sqrt(lrvar(X[,k]*e[,m])*T)
}
}
for(j in 1:nboot){
c[j]=max(abs(Smatrix.boot[,,j]/load))
}
lambda.boot = 2*quantile(c, 0.9)*sqrt(T)*1.1
reject_0.05 = rep(0,M)
for (m in 1:M){
# d[,m] = X %*% theta.matrix[m,] + innov1[,m]
#d[,m] = scale(d[,m])
# Y[,m] = alpha[m]*d[,m] + X %*% beta.matrix[m,] + innov2[,m]
#Y[,m] = scale(Y[,m])
#X = scale(X)
X.all = cbind(d[,m], X)
## step 1
fit1 =  rlasso(X.all, Y[,m], penalty = list(homoscedastic = "none", lambda.start = lambda.boot1))
#fit1 =  rlasso(X.all, Y[,m])
#fit1 =  rlasso(X.all, Y[,m], penalty = list(homoscedastic = "none", lambda.start = lambda.ga1))
beta.matrix.hat[m,] = fit1$beta[-1]
intercept.hat[m] = fit1$intercept
## step 2
fit2 =  rlasso(X, d[,m], penalty = list(homoscedastic = "none", lambda.start = lambda.boot))
#fit2 =  rlasso(X, d[,m])
#fit2 =  rlasso(X, d[,m], penalty = list(homoscedastic = "none", lambda.start = lambda.ga))
theta.matrix.hat[m,] = fit2$beta
v[,m] = d[,m] - predict(fit2)
#v[,m] = scale(v[,m])
y = Y[,m] - X %*% beta.matrix.hat[m,] - rep(intercept.hat[m], dim(Y)[1])
### LS-IV
#fit.iv = summary(ivreg(y ~ 0 + d[,m] | v[,m]))
#alpha.hat[m] = fit.iv$coefficients[,"Estimate"]
#psi[,m] = v[,m]*error
#sigma[m] = fit.iv$coefficients[,"Std. Error"]*sqrt(T)
### LS-IV
### LAD-IV
alpha0.hat[m] = fit1$beta[1]
b = sqrt(mean(d[,m]^2))*log(T)
alpha.hat[m] = optimize(med.iv, c(alpha0.hat[m]-10/b, alpha0.hat[m]+10/b), y = y, x = d[,m], z = v[,m])$minimum
#alpha.hat[m] = gridSearch(med.iv, levels = list(seq(alpha0.hat[m]-10/b, alpha0.hat[m]+10/b, length.out = 10000)), y = y, x = d[,m], z = v[,m], printDetail = FALSE)$minlevels
for(t in 1:T){
if((y[t] - alpha.hat[m]*d[t,m])<=0){psi[t,m]=-0.5*v[t,m]}else{psi[t,m]=0.5*v[t,m]}
}
### LAD-IV
error = y - alpha.hat[m]*d[,m]
ind    = which(density(error)$x == min(abs(density(error)$x)))
# if (length(ind) == 0) {
#   f = density(error)$y[which(density(error)$x == -min(abs(density(error)$x)))]
# } else {
#   f = density(error)$y[which(density(error)$x == min(abs(density(error)$x)))]
# }
f = npudens(tdat = error, edat = 0)$dens
omega[m] = lrvar(psi[,m])*T
phi[m] = mean(v[,m]^2*f)
sigma[m] = sqrt(omega[m]/phi[m]^2)
#### asymptotic individual inference
lower_0.05[m] = alpha.hat[m]-sigma[m]*qnorm(0.975)/sqrt(T)
upper_0.05[m] = alpha.hat[m]+sigma[m]*qnorm(0.975)/sqrt(T)
if(abs(alpha.hat[m]*sqrt(T)/sigma[m])>qnorm(0.975)){reject_0.05[m] = 1}
#### asymptotic individual inference
}
length_0.05 = upper_0.05 - lower_0.05
#results[[r]] = list(reject_0.05 = reject_0.05)
list(reject_0.05 = reject_0.05)
# list(length_0.05 = length_0.05, length.boot_0.05 = length.boot_0.05,
#      reject_0.05 = reject_0.05, reject.boot_0.05 = reject.boot_0.05, reject.boot.multi_0.05 = reject.boot.multi_0.05,
#      reject.boot.simul_0.05 = reject.boot.simul_0.05)
}
results = foreach(l=1:rep, .packages=c("mvtnorm", "hdm", "pracma", "np", "sandwich", "flare", "AER"), .inorder=FALSE) %dopar%{
sim_scene(nboot=nboot,T=T,K=K,M=M,rho=rho,rho.var=rho.var,lag=lag,dx=dx,dd=dd,cd=cd,cy=cy,bn=bn)
}
reject_0.05 = matrix(0,rep,M)
for(r in 1:rep){
reject_0.05[r,] = results[[r]]$reject_0.05
}
mean(colMeans(reject_0.05)[1:(M/2)])
FWER = 0
for(r in 1:rep){
if(length(which(results[[r]]$reject_0.05[(M/2+1):M]==1))>0){FWER = FWER + 1}
}
FWER/rep
results
seq(0,1,length.out = 10)
seq(0,5,length.out = 10)
library(RPostgres)
library(stringr)
library(chron)
library(zoo)
wrds <- dbConnect(Postgres(),
host='wrds-pgdata.wharton.upenn.edu',
port=9737,
user='huangche',
password='880329Hc__tj',
sslmode='require',
dbname='wrds')
wrds <- dbConnect(Postgres(),
host='wrds-pgdata.wharton.upenn.edu',
port=9737,
user='mknaus',
password='FoKoPro!135',
sslmode='require',
dbname='wrds')
date = "20170112"
ticker = "GM"
variables = "*"
statement.var = paste0(variables, collapse = ", ")
statement.id = paste("where sym_root = '", ticker, "'", sep = "")
statement.sql = paste("select", statement.var, "from", paste("ctm_", date, sep =""), statement.id)
res = dbSendQuery(wrds,statement.sql)
l=1
while(l+3<=6 && l<=6){}
while(l+3<=6 && l<=6){
l=l+1
print(l)
}
# needed only for package installation or update
library(devtools)
devtools::install_github("lborke/yamldebugger")
# load the package every time you want to use 'yamldebugger'
library(yamldebugger)
allKeywords
"plot" %in% allKeywords
setwd("C:")
setwd("C:/mac2/Quantlet/LASSO_Time_Space")
workdir = "C:/mac2/Quantlet/LASSO_Time_Space"
d_init = yaml.debugger.init(workdir, show_keywords = TRUE)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
d_results = yaml.debugger.run(qnames, d_init)
OverView = yaml.debugger.summary(qnames, d_results, summaryType = "mini")
d_init = yaml.debugger.init(workdir, show_keywords = TRUE)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
d_results = yaml.debugger.run(qnames, d_init)
OverView = yaml.debugger.summary(qnames, d_results, summaryType = "mini")
d_init = yaml.debugger.init(workdir, show_keywords = TRUE)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
d_results = yaml.debugger.run(qnames, d_init)
OverView = yaml.debugger.summary(qnames, d_results, summaryType = "mini")
d_init = yaml.debugger.init(workdir, show_keywords = TRUE)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
d_results = yaml.debugger.run(qnames, d_init)
OverView = yaml.debugger.summary(qnames, d_results, summaryType = "mini")
setwd("C:/mac2/Quantlet/LASSO_Time_Space/LTS_inference")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
library(formatR)
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", indent = 4, width.cutoff = 80, file = "LTS_inference.R")
setwd("C:/mac2/Quantlet/LASSO_Time_Space/LTS_lambda_system")
tidy_source( source = "LTS_lambda_system.R", indent = 4, width.cutoff = 80, file = "LTS_lambda_system.R")
setwd("C:/mac2/Quantlet/LASSO_Time_Space/LTS_inference")
tidy_source( source = "LTS_lambda_system.R", indent = 4, file = "LTS_lambda_system.R")
tidy_source( source = "LTS_inference.R", indent = 4,file = "LTS_inference.R")
d_init = yaml.debugger.init(workdir, show_keywords = TRUE)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
d_results = yaml.debugger.run(qnames, d_init)
OverView = yaml.debugger.summary(qnames, d_results, summaryType = "mini")
tidy_source( source = "LTS_inference.R", file = "LTS_inference.R")
library(formatR)
tidy_source( source = "LTS_inference.R", file = "LTS_inference.R")
tidy_source( source = "LTS_inference.R", file = "LTS_inference.R")
